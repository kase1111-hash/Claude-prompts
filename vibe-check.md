# Agentic Security Audit v2.0

## Post-Moltbook Edition — February 2026

> "I didn't write a single line of code." — Moltbook founder, days before 1.5M API keys were exposed
>
> This prompt exists because that sentence describes an increasing percentage of deployed software.

---

## PURPOSE

Perform a layered security audit of this codebase with specific attention to **agentic threat surfaces** — the class of vulnerabilities that emerge when AI agents handle credentials, execute code, install plugins, communicate with other agents, or operate on vibe-coded infrastructure that has never been security-reviewed.

This is not a generic OWASP checklist. This audit is designed for the reality of 2026: codebases authored or substantially generated by AI, deployed fast, handling real credentials, and often operating with agent-to-agent communication channels that introduce novel attack surfaces.

---

## AUDIT ARCHITECTURE

This audit operates in **five constitutional layers**, evaluated in order. Each layer gates the next — a critical failure at Layer 1 means Layer 2 findings are academic.

```
┌─────────────────────────────────────────────┐
│  LAYER 1: PROVENANCE & TRUST ORIGIN         │
│  Was this code reviewed by someone who       │
│  understands what it does?                   │
├─────────────────────────────────────────────┤
│  LAYER 2: CREDENTIAL & SECRET HYGIENE       │
│  How does this system handle keys, tokens,   │
│  and authentication material?                │
├─────────────────────────────────────────────┤
│  LAYER 3: AGENT BOUNDARY ENFORCEMENT        │
│  What can agents do, access, install, and    │
│  communicate — and who authorized it?        │
├─────────────────────────────────────────────┤
│  LAYER 4: SUPPLY CHAIN & DEPENDENCY TRUST   │
│  Where does external code/data come from,    │
│  and is it verified?                         │
├─────────────────────────────────────────────┤
│  LAYER 5: INFRASTRUCTURE & RUNTIME          │
│  Database config, access controls, hosting,  │
│  and deployment security                     │
└─────────────────────────────────────────────┘
```

---

## LAYER 1: PROVENANCE & TRUST ORIGIN

**The Moltbook Lesson:** The platform was entirely vibe-coded. No human ever reviewed the security architecture. The Supabase database shipped with public read/write access to all tables. This layer catches that class of failure before anything else matters.

### 1.1 Vibe-Code Detection

Scan for indicators that code was AI-generated without security review:

- [ ] **Test absence**: No test files, no test configuration, no CI test steps
- [ ] **Security configuration absence**: No `.env.example`, no secrets management, no auth middleware
- [ ] **Boilerplate signatures**: Repeated AI-style comments ("Here's how to...", "This function..."), uniform formatting across unrelated modules, TODO comments that read like prompts
- [ ] **Rapid commit history**: Massive initial commits, no iterative refinement, no security-related commit messages
- [ ] **README-to-code ratio**: Polished README with marketing language, minimal inline documentation, no SECURITY.md or CONTRIBUTING.md
- [ ] **Dependency count vs. project complexity**: Bloated dependencies for a simple project (the "npm install the universe" pattern)

**Severity:** If multiple vibe-code indicators are present AND the system handles credentials/PII/payments, flag as **CRITICAL** — the entire codebase should be treated as unreviewed.

### 1.2 Human Review Evidence

Look for signals that a security-conscious human has been involved:

- [ ] Security-focused commit messages (not just "fix bug")
- [ ] Threat model documentation (any form)
- [ ] Access control design decisions documented anywhere
- [ ] Evidence of security tooling in CI/CD (bandit, semgrep, npm audit, etc.)
- [ ] `.gitignore` that reflects security awareness (excludes `.env`, credentials, key files)

### 1.3 The "Tech Preview" Trap

**The Moltbook Lesson:** Founder described it as "a tech preview, a hobby" while 300k+ users were connected with real API keys.

- [ ] Does the project have production traffic or real users?
- [ ] Does it handle real credentials, even in "beta" or "preview"?
- [ ] Is there a mismatch between the project's claimed status (demo/alpha/hobby) and its actual exposure surface?
- [ ] Are there disclaimers that attempt to shift security responsibility to users without providing them tools to protect themselves?

**Severity:** Production traffic + real credentials + no security review = **CRITICAL** regardless of what the README calls it.

---

## LAYER 2: CREDENTIAL & SECRET HYGIENE

**The Moltbook Lesson:** 1.5 million API keys stored in plaintext. No encryption at rest. No row-level security. Keys for OpenAI, Anthropic, AWS, GitHub, and Google Cloud all accessible to anyone who found the database endpoint.

### 2.1 Secret Storage

- [ ] **Plaintext credentials anywhere**: Scan all files, database schemas, config files, environment files for plaintext API keys, passwords, tokens, connection strings
- [ ] **Client-side key exposure**: API keys, Supabase keys, Firebase keys, or any backend credentials visible in client-side JavaScript, HTML, or mobile app bundles
- [ ] **Backup persistence**: Do deleted credentials remain in backups, logs, or alternate storage? (Moltbook: removing credentials from UI didn't delete them from filesystem)
- [ ] **Git history leaks**: Have secrets ever been committed and then "removed"? They're still in git history. Run `gitleaks` or equivalent.
- [ ] **Environment variable handling**: Are `.env` files committed? Is there a `.env.example` showing expected variables without values?

### 2.2 Credential Scoping

- [ ] **Least privilege**: Are API keys scoped to minimum required permissions?
- [ ] **Key rotation**: Is there any mechanism for rotating credentials? Any rotation schedule?
- [ ] **Per-user vs. shared keys**: Does the system use one master key for all users, or are credentials properly isolated?
- [ ] **Credential delegation chain**: If users provide their API keys, trace the full path — where are they stored, who/what can access them, are they ever logged, are they transmitted in plaintext?

### 2.3 Machine Credential Exposure

This is the novel category Moltbook created — not human passwords, but **machine-to-machine credentials** that agents use to act on behalf of users.

- [ ] **OAuth token storage**: Are OAuth tokens stored with the same rigor as passwords?
- [ ] **API key as identity**: Is an API key the only thing separating one user's agent from another's?
- [ ] **Credential aggregation risk**: Does the system create a single point of failure where many users' credentials are stored together? (Moltbook: single database table with 1.5M keys)
- [ ] **Key revocation path**: If credentials are exposed, can users revoke them without losing their account/data?

---

## LAYER 3: AGENT BOUNDARY ENFORCEMENT

**The Moltbook Lesson:** Agents had file system access, command execution, and network communication. Agents on the platform asked other agents to run destructive commands. Malicious "skills" were uploaded and automatically installed. No boundary existed between legitimate automation and prompt injection.

### 3.1 Agent Permission Model

- [ ] **Default permissions**: What can an agent do out of the box? Is the default ALLOW or DENY?
- [ ] **Privilege escalation paths**: Can an agent acquire permissions it wasn't initially granted?
- [ ] **File system access**: What directories/files can agents read/write/execute?
- [ ] **Network access**: Can agents make arbitrary network requests? To what destinations?
- [ ] **Command execution**: Can agents execute shell commands? With what user privileges?
- [ ] **Cross-agent communication**: Can agents send instructions to other agents? Are these instructions validated?

### 3.2 Prompt Injection Defense

- [ ] **Input sanitization**: Are external inputs (user messages, web content, file contents, agent messages) sanitized before being included in prompts?
- [ ] **Output validation**: Are agent outputs validated against expected schemas before being executed?
- [ ] **Instruction hierarchy**: Is there a clear separation between system instructions and user/external input?
- [ ] **Context poisoning**: Can an attacker influence an agent's context window through indirect means (e.g., content on a webpage the agent reads, metadata in a file)?

### 3.3 Time-Shifted Prompt Injection

**This is a 2026-specific threat vector.** Security researchers have documented attacks where:
1. An agent reads seemingly harmless content
2. The content contains fragments that are individually benign
3. Over time, the agent accumulates enough fragments to form a complete malicious instruction
4. The payload activates days or weeks after initial exposure

- [ ] **Memory persistence**: Does the agent maintain long-term memory or context across sessions?
- [ ] **Memory provenance**: Is the source of each memory/context item tracked?
- [ ] **Accumulated context review**: Is there any mechanism to audit what's in an agent's accumulated context?
- [ ] **Memory isolation**: Are memories from untrusted sources isolated from system-level context?

### 3.4 Agent-to-Agent Trust

- [ ] **Identity verification**: When agents communicate, is the identity of the sending agent verified?
- [ ] **Instruction validation**: Are instructions from other agents treated as untrusted input?
- [ ] **Capability delegation**: Can one agent grant capabilities to another? Is this logged?
- [ ] **Social engineering surface**: Can a malicious agent manipulate a legitimate agent through conversational patterns?

---

## LAYER 4: SUPPLY CHAIN & DEPENDENCY TRUST

**The Moltbook Lesson:** 22-26% of skills in the OpenClaw ecosystem contained vulnerabilities. A security researcher uploaded a benign skill, artificially inflated its download count, and watched developers from seven countries download it within hours. The skill could have executed any command on their systems.

### 4.1 Plugin/Skill Supply Chain

If the project uses or distributes plugins, skills, extensions, or MCP servers:

- [ ] **Provenance verification**: Are plugins/skills signed by their authors?
- [ ] **Code review before installation**: Is plugin code reviewed (by human or automated tooling) before it runs?
- [ ] **Permission manifest**: Do plugins declare what permissions they need? Are those declarations enforced?
- [ ] **Automatic installation**: Can agents install plugins without human approval?
- [ ] **Download count manipulation**: Can install/download metrics be faked to create false trust signals?
- [ ] **Typosquatting defense**: Are there protections against malicious packages with names similar to legitimate ones?
- [ ] **Update integrity**: When plugins update, is the update verified against the original author's signature?

### 4.2 MCP Server Trust

Model Context Protocol servers are the new critical infrastructure. A compromised MCP server is a SolarWinds-class event for the agent ecosystem.

- [ ] **MCP server enumeration**: List all MCP servers this project connects to or provides
- [ ] **Server authentication**: How does the system verify it's connecting to the legitimate MCP server?
- [ ] **Data exposure**: What data flows through each MCP server? Is any of it sensitive?
- [ ] **Failure mode**: What happens if an MCP server is compromised? Does the agent fail safe or fail open?
- [ ] **Local vs. remote**: Are MCP servers running locally or connecting to remote endpoints?
- [ ] **Tool injection**: Can a malicious MCP server inject tools that the agent will use unknowingly?

### 4.3 Traditional Dependency Audit

- [ ] **Known vulnerabilities**: Run `npm audit`, `pip-audit`, or equivalent. Report HIGH and CRITICAL findings.
- [ ] **Abandoned dependencies**: Flag any dependency not updated in 12+ months
- [ ] **Dependency count**: Is the dependency count proportionate to project complexity?
- [ ] **Transitive dependencies**: Are transitive dependencies audited, or only direct ones?
- [ ] **License compatibility**: Are all dependency licenses compatible with the project's intended use?
- [ ] **Pinned versions**: Are dependency versions pinned, or floating on `latest`/`^`/`~`?

---

## LAYER 5: INFRASTRUCTURE & RUNTIME

**The Moltbook Lesson:** Supabase Row Level Security was either misconfigured or not enabled. The database was publicly accessible with the API key exposed in client-side JavaScript. This is a textbook infrastructure failure that no amount of application-level security can compensate for.

### 5.1 Database Security

- [ ] **Row Level Security (RLS)**: If using Supabase, Firebase, or any row-level security system — is it actually enabled and correctly configured? **Verify, don't assume.**
- [ ] **Public access**: Can the database be accessed without authentication?
- [ ] **API key exposure**: Is the database API key/connection string visible in client-side code?
- [ ] **Read/write separation**: Is read access properly separated from write access?
- [ ] **Table-by-table audit**: For each table containing sensitive data, verify that access controls exist and are correct
- [ ] **Admin access**: Is there a separate admin path, or does the main application connection have full privileges?

### 5.2 Backend-as-a-Service (BaaS) Configuration

The rise of vibe-coding has created a specific vulnerability class: developers using Supabase, Firebase, Appwrite, etc. without understanding their security models.

- [ ] **Default configuration audit**: Has the BaaS been configured beyond defaults? Most BaaS platforms ship with permissive defaults.
- [ ] **Authentication configuration**: Is email/password auth properly configured? Are social auth redirects validated?
- [ ] **Storage bucket permissions**: Are file storage buckets properly locked down?
- [ ] **Edge function security**: Are serverless/edge functions validating their inputs?
- [ ] **Realtime channel security**: If using realtime features, are channels properly secured?

### 5.3 Network & Hosting

- [ ] **HTTPS everywhere**: Are all connections encrypted in transit?
- [ ] **CORS configuration**: Is CORS configured to allow only expected origins, or is it `*`?
- [ ] **Rate limiting**: Are API endpoints rate-limited to prevent abuse?
- [ ] **DDoS protection**: Is there any protection against denial-of-service?
- [ ] **Logging**: Are security-relevant events logged? Are logs stored securely?
- [ ] **Error exposure**: Do error messages leak internal details (stack traces, file paths, database queries)?

### 5.4 Deployment Pipeline

- [ ] **CI/CD security**: Are build/deploy pipelines using pinned actions/images?
- [ ] **Secret injection**: Are secrets injected at runtime, not baked into images/artifacts?
- [ ] **Environment separation**: Are dev/staging/production environments properly isolated?
- [ ] **Rollback capability**: Can the system be rolled back quickly if a security issue is discovered?

---

## REPORT FORMAT

Generate findings in the following structure:

### AUDIT METADATA
```
Project:          [name]
Audit Date:       [date]
Audit Prompt:     Agentic Security Audit v2.0
Auditor:          [Claude model identifier]
Codebase Hash:    [git commit hash if available]
Strictness:       [STANDARD | STRICT | MAXIMUM]
Context:          [PROTOTYPE | INTERNAL | PRODUCTION | PUBLIC-INFRA]
```

### PROVENANCE ASSESSMENT
```
Vibe-Code Confidence:    [0-100]% — how likely this was AI-generated without security review
Human Review Evidence:   [NONE | MINIMAL | MODERATE | STRONG]
Tech Preview Trap:       [YES | NO | UNCLEAR]
```

### LAYER VERDICTS
```
Layer 1 — Provenance:        [PASS | WARN | FAIL | CRITICAL]
Layer 2 — Credentials:       [PASS | WARN | FAIL | CRITICAL]
Layer 3 — Agent Boundaries:  [PASS | WARN | FAIL | CRITICAL]
Layer 4 — Supply Chain:      [PASS | WARN | FAIL | CRITICAL]
Layer 5 — Infrastructure:    [PASS | WARN | FAIL | CRITICAL]
```

### FINDING SEVERITY SCALE

| Severity | Definition | Response |
|----------|-----------|----------|
| **CRITICAL** | Active or imminent data exposure. Exploitable without authentication. Production credentials at risk. | **Stop. Fix before any other work.** |
| **HIGH** | Significant vulnerability requiring specific conditions to exploit. Credential mishandling without active exposure. | **Fix within 24 hours.** |
| **MEDIUM** | Defense-in-depth gap. Missing security control that other controls partially compensate for. | **Fix within 1 week.** |
| **LOW** | Best practice violation. Theoretical risk. Hygiene improvement. | **Fix when convenient.** |
| **INFO** | Observation. Pattern worth noting. Not a vulnerability. | **Awareness only.** |

### FINDINGS

For each finding:

```
[SEVERITY] — [SHORT TITLE]
Layer:     [1-5]
Location:  [file:line or system component]
Evidence:  [what was found]
Risk:      [what could happen]
Fix:       [specific remediation steps]
Reference: [CVE, OWASP, or incident reference if applicable]
```

### POSITIVE FINDINGS

What this codebase does well. Security is also about recognizing good practices so they're maintained.

### RECOMMENDED ACTIONS

Prioritized list:
1. [ ] **Immediate** (do today): ...
2. [ ] **Short-term** (this week): ...
3. [ ] **Medium-term** (this month): ...
4. [ ] **Long-term** (this quarter): ...

---

## CONFIGURATION

Set these parameters before running:

```
Strictness:   STANDARD    # STANDARD | STRICT | MAXIMUM
Context:      PRODUCTION  # PROTOTYPE | INTERNAL | PRODUCTION | PUBLIC-INFRA
Focus:        ALL         # ALL | CREDENTIALS | AGENTS | SUPPLY-CHAIN | INFRASTRUCTURE
Skip-Layers:  NONE        # Comma-separated layer numbers to skip, or NONE
```

- **STANDARD**: Flags clear vulnerabilities and missing best practices
- **STRICT**: Also flags defense-in-depth gaps and theoretical risks
- **MAXIMUM**: Treats every missing security control as a finding. For production systems handling credentials or PII.

---

## INCIDENT REFERENCES

This audit was informed by the following real-world incidents:

| Incident | Date | Root Cause | Lesson |
|----------|------|-----------|--------|
| Moltbook database exposure | Jan 31 2026 | Supabase RLS misconfiguration, plaintext API keys, vibe-coded without review | Layers 1, 2, 5 |
| MoltBot/OpenClaw supply chain | Jan 2026 | Unsigned skills, no code review, inflatable download metrics | Layers 3, 4 |
| Moltbook agent-to-agent attacks | Feb 2026 | Agents executing instructions from untrusted agents, no boundary enforcement | Layer 3 |
| ClawdHub skill poisoning | Feb 2026 | Malicious skills with legitimate appearance, credential stealers disguised as utilities | Layer 4 |

---

## VERSION HISTORY

| Version | Date | Changes |
|---------|------|---------|
| 1.0 | Dec 2025 | Initial agentic security audit prompt |
| 2.0 | Feb 2026 | Post-Moltbook rewrite. Added: layered architecture, vibe-code detection, agent boundary enforcement, MCP server trust, time-shifted prompt injection, BaaS configuration audit, credential delegation chains, supply chain trust metrics. Restructured from flat checklist to constitutional layers. |

---

## LICENSE

CC0 1.0 Universal — Public Domain

This prompt is dedicated to the public domain. Use it, modify it, redistribute it. The more codebases that get audited, the fewer Moltbook-class incidents we'll see.

---

*"The agent usefulness correlates directly with access level. Sandboxing solves security but cripples functionality." — This is the central tension of agentic security. This audit doesn't pretend to resolve it. It makes the tradeoffs visible so humans can decide.*
